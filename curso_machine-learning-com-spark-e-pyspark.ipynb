{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 01 Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.136:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>machine-learning-pyspark-mllib</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe2c8c43490>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    VectorAssembler,\n",
    "    PCA,\n",
    "    Binarizer,\n",
    "    StringIndexer,\n",
    "    IndexToString,\n",
    "    OneHotEncoder,\n",
    "    Imputer,\n",
    "    PolynomialExpansion,\n",
    "    Normalizer,\n",
    "    StandardScaler,\n",
    "    RobustScaler,\n",
    "    MinMaxScaler,\n",
    "    MaxAbsScaler,\n",
    "    QuantileDiscretizer,\n",
    "    RFormula,\n",
    "    VectorSlicer,\n",
    "    ChiSqSelector,\n",
    "    UnivariateFeatureSelector\n",
    ")\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('machine-learning-pyspark-mllib')\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando CSV, Parquet, JSON e ORC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------+-------------+------+----------+\n",
      "| id|               nome|status|       cidade|vendas|      data|\n",
      "+---+-------------------+------+-------------+------+----------+\n",
      "|  1|   Carminda Pestana| Ativo|  Santa Maria|    23|2020-08-11|\n",
      "|  2|    Deolinda Vilela| Ativo|Novo Hamburgo|    34|2020-03-05|\n",
      "|  3|   Emídio Dornelles| Ativo| Porto Alegre|    34|2020-02-05|\n",
      "|  4|Felisbela Dornelles| Ativo| Porto Alegre|    36|2020-02-05|\n",
      "|  5|     Graça Ornellas| Ativo| Porto Alegre|    12|2020-02-05|\n",
      "|  6|   Matilde Rebouças| Ativo| Porto Alegre|    22|2019-01-05|\n",
      "|  7|    Noêmia   Orriça| Ativo|  Santa Maria|    45|2019-10-05|\n",
      "|  8|      Roque Vásquez| Ativo| Porto Alegre|    65|2020-03-05|\n",
      "|  9|      Uriel Queiroz| Ativo| Porto Alegre|    54|2018-05-05|\n",
      "| 10|   Viviana Sequeira| Ativo| Porto Alegre|     0|2020-09-05|\n",
      "+---+-------------------+------+-------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# csv\n",
    "schema = \"\"\"\n",
    "    id INT,\n",
    "    nome STRING,\n",
    "    status STRING,\n",
    "    cidade STRING,\n",
    "    vendas INT,\n",
    "    data DATE \n",
    "\"\"\"\n",
    "df_despachantes = (\n",
    "    spark.read.format('csv')\n",
    "    .schema(schema=schema)\n",
    "    .load('data/despachantes.csv')\n",
    ")\n",
    "df_despachantes.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----+-------------+---+----------+\n",
      "|_c0|                _c1|  _c2|          _c3|_c4|       _c5|\n",
      "+---+-------------------+-----+-------------+---+----------+\n",
      "|  1|   Carminda Pestana|Ativo|  Santa Maria| 23|2020-08-11|\n",
      "|  2|    Deolinda Vilela|Ativo|Novo Hamburgo| 34|2020-03-05|\n",
      "|  3|   Emídio Dornelles|Ativo| Porto Alegre| 34|2020-02-05|\n",
      "|  4|Felisbela Dornelles|Ativo| Porto Alegre| 36|2020-02-05|\n",
      "|  5|     Graça Ornellas|Ativo| Porto Alegre| 12|2020-02-05|\n",
      "|  6|   Matilde Rebouças|Ativo| Porto Alegre| 22|2019-01-05|\n",
      "|  7|    Noêmia   Orriça|Ativo|  Santa Maria| 45|2019-10-05|\n",
      "|  8|      Roque Vásquez|Ativo| Porto Alegre| 65|2020-03-05|\n",
      "|  9|      Uriel Queiroz|Ativo| Porto Alegre| 54|2018-05-05|\n",
      "| 10|   Viviana Sequeira|Ativo| Porto Alegre|  0|2020-09-05|\n",
      "+---+-------------------+-----+-------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parquet\n",
    "df_despachantes = (\n",
    "    spark.read.format('parquet')\n",
    "    .option('inferSchema', True)\n",
    "    .load('data/despachantes.parquet')\n",
    ")\n",
    "df_despachantes.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+---+-------------------+------+------+\n",
      "|       cidade|       data| id|               nome|status|vendas|\n",
      "+-------------+-----------+---+-------------------+------+------+\n",
      "|  Santa Maria| 2020-08-11|  1|   Carminda Pestana| Ativo|    23|\n",
      "|Novo Hamburgo| 2020-03-05|  2|    Deolinda Vilela| Ativo|    34|\n",
      "| Porto Alegre| 2020-02-05|  3|   Emídio Dornelles| Ativo|    34|\n",
      "| Porto Alegre| 2020-02-05|  4|Felisbela Dornelles| Ativo|    36|\n",
      "| Porto Alegre| 2020-02-05|  5|     Graça Ornellas| Ativo|    12|\n",
      "| Porto Alegre| 2019-01-05|  6|   Matilde Rebouças| Ativo|    22|\n",
      "|  Santa Maria| 2019-10-05|  7|    Noêmia   Orriça| Ativo|    45|\n",
      "| Porto Alegre| 2020-03-05|  8|      Roque Vásquez| Ativo|    65|\n",
      "| Porto Alegre| 2018-05-05|  9|      Uriel Queiroz| Ativo|    54|\n",
      "| Porto Alegre| 2020-09-05| 10|   Viviana Sequeira| Ativo|     0|\n",
      "+-------------+-----------+---+-------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JSON\n",
    "df_despachantes = (\n",
    "    spark.read.format('json')\n",
    "    .option('inferSchema', True)\n",
    "    .load('data/despachantes.json')\n",
    ")\n",
    "df_despachantes.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----+-------------+---+----------+\n",
      "|_c0|                _c1|  _c2|          _c3|_c4|       _c5|\n",
      "+---+-------------------+-----+-------------+---+----------+\n",
      "|  1|   Carminda Pestana|Ativo|  Santa Maria| 23|2020-08-11|\n",
      "|  2|    Deolinda Vilela|Ativo|Novo Hamburgo| 34|2020-03-05|\n",
      "|  3|   Emídio Dornelles|Ativo| Porto Alegre| 34|2020-02-05|\n",
      "|  4|Felisbela Dornelles|Ativo| Porto Alegre| 36|2020-02-05|\n",
      "|  5|     Graça Ornellas|Ativo| Porto Alegre| 12|2020-02-05|\n",
      "|  6|   Matilde Rebouças|Ativo| Porto Alegre| 22|2019-01-05|\n",
      "|  7|    Noêmia   Orriça|Ativo|  Santa Maria| 45|2019-10-05|\n",
      "|  8|      Roque Vásquez|Ativo| Porto Alegre| 65|2020-03-05|\n",
      "|  9|      Uriel Queiroz|Ativo| Porto Alegre| 54|2018-05-05|\n",
      "| 10|   Viviana Sequeira|Ativo| Porto Alegre|  0|2020-09-05|\n",
      "+---+-------------------+-----+-------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ORC\n",
    "df_despachantes = (\n",
    "    spark.read.format('orc')\n",
    "    .option('inferSchema', True)\n",
    "    .load('data/despachantes.orc')\n",
    ")\n",
    "df_despachantes.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engenharia de Atributos e Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 03 - Vetorização de Atributos com VectorAssembler\n",
    "- Recebe como entrada um data frame com diversos atributos\n",
    "- Produz como saída um único atributo, que é um vetor dos atributos de\n",
    "entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors|HP |\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|21     |6        |160        |39             |262 |1646 |0        |1          |4      |4          |110|\n",
      "|21     |6        |160        |39             |2875|1702 |0        |1          |4      |4          |110|\n",
      "|228    |4        |108        |385            |232 |1861 |1        |1          |4      |1          |93 |\n",
      "|214    |6        |258        |308            |3215|1944 |1        |0          |3      |1          |110|\n",
      "|187    |8        |360        |315            |344 |1702 |0        |0          |3      |2          |175|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_carros = (\n",
    "    spark.read.format('csv')\n",
    "    .option('inferSchema', True)\n",
    "    .option('header', True)\n",
    "    .option('delimiter', ';')\n",
    "    .load('data/Carros.csv')\n",
    ")\n",
    "df_carros.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+\n",
      "|features                                             |\n",
      "+-----------------------------------------------------+\n",
      "|[21.0,6.0,160.0,39.0,262.0,1646.0,0.0,1.0,4.0,4.0]   |\n",
      "|[21.0,6.0,160.0,39.0,2875.0,1702.0,0.0,1.0,4.0,4.0]  |\n",
      "|[228.0,4.0,108.0,385.0,232.0,1861.0,1.0,1.0,4.0,1.0] |\n",
      "|[214.0,6.0,258.0,308.0,3215.0,1944.0,1.0,0.0,3.0,1.0]|\n",
      "|[187.0,8.0,360.0,315.0,344.0,1702.0,0.0,0.0,3.0,2.0] |\n",
      "+-----------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_carros_vector_assembler = VectorAssembler(\n",
    "    inputCols=df_carros.columns[:-1],\n",
    "    outputCol='features'\n",
    ").transform(df_carros)\n",
    "\n",
    "df_carros_vector_assembler.select('features').show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Aula 04 - Geração de Caracterśticas com PCA (Principal Component analysis)\n",
    "\n",
    "- Alta dimensionalidade:\n",
    "    - Menor capacidade de generalização\n",
    "- PCA: Redução de Dimensionalidade\n",
    "- Cria atributos sintéticos, sem compreensão funcional\n",
    "- Estes novos atributos buscam manter as características importantes dos dados\n",
    "- Representação dos atributos originais: projeção\n",
    "- Não permite avaliar importância de atributos e não mais representam o negocio\n",
    "analisado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+-----------------------------------------------------------+\n",
      "|features                                             |features_pca                                               |\n",
      "+-----------------------------------------------------+-----------------------------------------------------------+\n",
      "|[21.0,6.0,160.0,39.0,262.0,1646.0,0.0,1.0,4.0,4.0]   |[618.7707206779613,-937.712394997354,1231.963352994551]    |\n",
      "|[21.0,6.0,160.0,39.0,2875.0,1702.0,0.0,1.0,4.0,4.0]  |[3112.9887675342197,-161.05746385491523,1191.8619913054383]|\n",
      "|[228.0,4.0,108.0,385.0,232.0,1861.0,1.0,1.0,4.0,1.0] |[640.4959007710695,-1120.718886511042,1320.0756315189049]  |\n",
      "|[214.0,6.0,258.0,308.0,3215.0,1944.0,1.0,0.0,3.0,1.0]|[3466.0956877556673,-149.69421418298353,1401.204178036853] |\n",
      "|[187.0,8.0,360.0,315.0,344.0,1702.0,0.0,0.0,3.0,2.0] |[661.4577445758732,-812.4592128844115,1395.2949328316356]  |\n",
      "+-----------------------------------------------------+-----------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_modelo = PCA(\n",
    "    k=3,\n",
    "    inputCol='features',\n",
    "    outputCol='features_pca'\n",
    ").fit(df_carros_vector_assembler)\n",
    "\n",
    "df_carros_pca = pca_modelo.transform(df_carros_vector_assembler)\n",
    "df_carros_pca.select('features', 'features_pca').show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 05 - Binarização de Atributos\n",
    "- Parametro threshold\n",
    "- \\> threshold = 1\n",
    "- < threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----------+\n",
      "|sepallength|sepalwidth|petallength|petalwidth|      class|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "|        5.1|       3.5|        1.4|       0.2|Iris-setosa|\n",
      "|        4.9|       3.0|        1.4|       0.2|Iris-setosa|\n",
      "|        4.7|       3.2|        1.3|       0.2|Iris-setosa|\n",
      "|        4.6|       3.1|        1.5|       0.2|Iris-setosa|\n",
      "|        5.0|       3.6|        1.4|       0.2|Iris-setosa|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_iris = (\n",
    "    spark.read.format('csv')\n",
    "    .option('inferSchema', True)\n",
    "    .option('header', True)\n",
    "    .load('data/iris.csv')\n",
    ")\n",
    "\n",
    "df_iris.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----------+---------------------+\n",
      "|sepallength|sepalwidth|petallength|petalwidth|      class|sepallength_binarizer|\n",
      "+-----------+----------+-----------+----------+-----------+---------------------+\n",
      "|        5.1|       3.5|        1.4|       0.2|Iris-setosa|                  1.0|\n",
      "|        4.9|       3.0|        1.4|       0.2|Iris-setosa|                  0.0|\n",
      "|        4.7|       3.2|        1.3|       0.2|Iris-setosa|                  0.0|\n",
      "|        4.6|       3.1|        1.5|       0.2|Iris-setosa|                  0.0|\n",
      "|        5.0|       3.6|        1.4|       0.2|Iris-setosa|                  1.0|\n",
      "+-----------+----------+-----------+----------+-----------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_iris_binarizer = Binarizer(\n",
    "    threshold=4.9,\n",
    "    inputCol='sepallength',\n",
    "    outputCol='sepallength_binarizer'\n",
    ").transform(df_iris)\n",
    "\n",
    "df_iris_binarizer.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 06 - Indexação de Texto com StringIndexer\n",
    "\n",
    "- Técnica de Categorical Encoding: transforma categorias em números\n",
    "- Itens mais frequentes recebem os números menores\n",
    "- Você cria um modelo com um conjunto de dados, e usar este modelo para transformar outros conjuntos de dados\n",
    "    - Rótulos não conhecidos encontrados são tratados pelo parâmetro handleInvalid, que pode ter os valores\n",
    "        - Exceção (default): ‘error’\n",
    "        - Omitir: 'skip'\n",
    "        - Colocar “desconhecidos” em uma categoria especial: 'keep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|CreditScore|Geography|Gender|Age|Tenure| Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|        619|   France|Female| 42|     2|       0|            1|        1|             1|       10134888|     1|\n",
      "|        608|    Spain|Female| 41|     1| 8380786|            1|        0|             1|       11254258|     0|\n",
      "|        502|   France|Female| 42|     8| 1596608|            3|        1|             0|       11393157|     1|\n",
      "|        699|   France|Female| 39|     1|       0|            2|        0|             0|        9382663|     0|\n",
      "|        850|    Spain|Female| 43|     2|12551082|            1|        1|             1|         790841|     0|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_churn = (\n",
    "    spark.read.format('csv')\n",
    "    .option('header', True)\n",
    "    .option('inferSchema', True)\n",
    "    .option('delimiter', ';')\n",
    "    .load('data/Churn.csv')\n",
    ")\n",
    "\n",
    "df_churn.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+------+----------+\n",
      "|Geography|Geography_idx|Gender|Gender_idx|\n",
      "+---------+-------------+------+----------+\n",
      "|   France|          0.0|Female|       1.0|\n",
      "|    Spain|          2.0|Female|       1.0|\n",
      "|   France|          0.0|Female|       1.0|\n",
      "|   France|          0.0|Female|       1.0|\n",
      "|    Spain|          2.0|Female|       1.0|\n",
      "+---------+-------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Geography</th><th>Gender</th><th>count(Geography_idx)</th><th>count(Gender_idx)</th></tr>\n",
       "<tr><td>Germany</td><td>Female</td><td>1193</td><td>1193</td></tr>\n",
       "<tr><td>France</td><td>Male</td><td>2753</td><td>2753</td></tr>\n",
       "<tr><td>France</td><td>Female</td><td>2261</td><td>2261</td></tr>\n",
       "<tr><td>Spain</td><td>Male</td><td>1388</td><td>1388</td></tr>\n",
       "<tr><td>Germany</td><td>Male</td><td>1316</td><td>1316</td></tr>\n",
       "<tr><td>Spain</td><td>Female</td><td>1089</td><td>1089</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+------+--------------------+-----------------+\n",
       "|Geography|Gender|count(Geography_idx)|count(Gender_idx)|\n",
       "+---------+------+--------------------+-----------------+\n",
       "|  Germany|Female|                1193|             1193|\n",
       "|   France|  Male|                2753|             2753|\n",
       "|   France|Female|                2261|             2261|\n",
       "|    Spain|  Male|                1388|             1388|\n",
       "|  Germany|  Male|                1316|             1316|\n",
       "|    Spain|Female|                1089|             1089|\n",
       "+---------+------+--------------------+-----------------+"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_churn_string_idx = StringIndexer(\n",
    "    inputCols=['Geography', 'Gender'],\n",
    "    outputCols=['Geography_idx', 'Gender_idx']\n",
    ").fit(df_churn)\n",
    "\n",
    "df_churn_string_idx = model_churn_string_idx.transform(df_churn)\n",
    "df_churn_string_idx.select('Geography',\n",
    "                           'Geography_idx',\n",
    "                           'Gender',\n",
    "                           'Gender_idx'\n",
    "                           ).show(5)\n",
    "\n",
    "df_churn_string_idx.groupBy('Geography', 'Gender').agg(\n",
    "    F.count('Geography_idx'), F.count('Gender_idx'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 7 - Índice para Texto com IndexToString\n",
    "- As vezes precisamos converter de volta um\n",
    "índice para a categoria\n",
    "    - Explicar o modelo\n",
    "    - Mostrar valores “reais”\n",
    "- IndexToString cria um atributo com a coluna original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------------------+\n",
      "|Geography|Geography_idx|Geography_idx_to_str|\n",
      "+---------+-------------+--------------------+\n",
      "|   France|          0.0|              France|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|   France|          0.0|              France|\n",
      "|   France|          0.0|              France|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|   France|          0.0|              France|\n",
      "|  Germany|          1.0|             Germany|\n",
      "|   France|          0.0|              France|\n",
      "|   France|          0.0|              France|\n",
      "|   France|          0.0|              France|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|   France|          0.0|              France|\n",
      "|   France|          0.0|              France|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|  Germany|          1.0|             Germany|\n",
      "|  Germany|          1.0|             Germany|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|   France|          0.0|              France|\n",
      "+---------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_churn_index_to_string = IndexToString(\n",
    "    inputCol='Geography_idx',\n",
    "    outputCol='Geography_idx_to_str'\n",
    ").transform(df_churn_string_idx)\n",
    "\n",
    "df_churn_index_to_string.select(\n",
    "    'Geography', 'Geography_idx', 'Geography_idx_to_str').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 08 - One Hot Encoding\n",
    "- OneHotEncoding produz um único atributo de saída com uma matriz densa, a partir de n atributos numéricos\n",
    "-  Espera atributos numéricos: Podemos usar StringIndexer para transformar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------------+----------+-----------------------+--------------------+\n",
      "|Geography|Gender|Geography_idx|Gender_idx|Geography_oneHotEncoder|Gender_oneHotEncoder|\n",
      "+---------+------+-------------+----------+-----------------------+--------------------+\n",
      "|France   |Female|0.0          |1.0       |(2,[0],[1.0])          |(1,[],[])           |\n",
      "|Spain    |Female|2.0          |1.0       |(2,[],[])              |(1,[],[])           |\n",
      "|France   |Female|0.0          |1.0       |(2,[0],[1.0])          |(1,[],[])           |\n",
      "|France   |Female|0.0          |1.0       |(2,[0],[1.0])          |(1,[],[])           |\n",
      "|Spain    |Female|2.0          |1.0       |(2,[],[])              |(1,[],[])           |\n",
      "|Spain    |Male  |2.0          |0.0       |(2,[],[])              |(1,[0],[1.0])       |\n",
      "|France   |Male  |0.0          |0.0       |(2,[0],[1.0])          |(1,[0],[1.0])       |\n",
      "|Germany  |Female|1.0          |1.0       |(2,[1],[1.0])          |(1,[],[])           |\n",
      "+---------+------+-------------+----------+-----------------------+--------------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_one_hot_encoding = OneHotEncoder(\n",
    "    inputCols=['Geography_idx', 'Gender_idx'],\n",
    "    outputCols=['Geography_oneHotEncoder', 'Gender_oneHotEncoder']\n",
    "\n",
    ").fit(df_churn_string_idx)\n",
    "\n",
    "df_one_hot_encoding = model_one_hot_encoding.transform(df_churn_string_idx)\n",
    "df_one_hot_encoding.select('Geography', 'Gender', 'Geography_idx', 'Gender_idx',\n",
    "                           'Geography_oneHotEncoder', 'Gender_oneHotEncoder').show(8, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+-------------+----------+-----------------------+--------------------+\n",
    "# |CreditScore|Geography|Gender|Age|Tenure| Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|Geography_idx|Gender_idx|Geography_oneHotEncoder|Gender_oneHotEncoder|\n",
    "# +-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+-------------+----------+-----------------------+--------------------+\n",
    "# |        619|   France|Female| 42|     2|       0|            1|        1|             1|       10134888|     1|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# |        608|    Spain|Female| 41|     1| 8380786|            1|        0|             1|       11254258|     0|          2.0|       1.0|              (2,[],[])|           (1,[],[])|\n",
    "# |        502|   France|Female| 42|     8| 1596608|            3|        1|             0|       11393157|     1|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# |        699|   France|Female| 39|     1|       0|            2|        0|             0|        9382663|     0|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# |        850|    Spain|Female| 43|     2|12551082|            1|        1|             1|         790841|     0|          2.0|       1.0|              (2,[],[])|           (1,[],[])|\n",
    "# |        645|    Spain|  Male| 44|     8|11375578|            2|        1|             0|       14975671|     1|          2.0|       0.0|              (2,[],[])|       (1,[0],[1.0])|\n",
    "# |        822|   France|  Male| 50|     7|       0|            2|        1|             1|         100628|     0|          0.0|       0.0|          (2,[0],[1.0])|       (1,[0],[1.0])|\n",
    "# |        376|  Germany|Female| 29|     4|11504674|            4|        1|             0|       11934688|     1|          1.0|       1.0|          (2,[1],[1.0])|           (1,[],[])|\n",
    "# |        501|   France|  Male| 44|     4|14205107|            2|        0|             1|         749405|     0|          0.0|       0.0|          (2,[0],[1.0])|       (1,[0],[1.0])|\n",
    "# |        684|   France|  Male| 27|     2|13460388|            1|        1|             1|        7172573|     0|          0.0|       0.0|          (2,[0],[1.0])|       (1,[0],[1.0])|\n",
    "# |        528|   France|  Male| 31|     6|10201672|            2|        0|             0|        8018112|     0|          0.0|       0.0|          (2,[0],[1.0])|       (1,[0],[1.0])|\n",
    "# |        497|    Spain|  Male| 24|     3|       0|            2|        1|             0|        7639001|     0|          2.0|       0.0|              (2,[],[])|       (1,[0],[1.0])|\n",
    "# |        476|   France|Female| 34|    10|       0|            2|        1|             0|        2626098|     0|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# |        549|   France|Female| 25|     5|       0|            2|        0|             0|       19085779|     0|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# |        635|    Spain|Female| 35|     7|       0|            2|        1|             1|        6595165|     0|          2.0|       1.0|              (2,[],[])|           (1,[],[])|\n",
    "# |        616|  Germany|  Male| 45|     3|14312941|            2|        0|             1|        6432726|     0|          1.0|       0.0|          (2,[1],[1.0])|       (1,[0],[1.0])|\n",
    "# |        653|  Germany|  Male| 58|     1|13260288|            1|        1|             0|         509767|     1|          1.0|       0.0|          (2,[1],[1.0])|       (1,[0],[1.0])|\n",
    "# |        549|    Spain|Female| 24|     9|       0|            2|        1|             1|        1440641|     0|          2.0|       1.0|              (2,[],[])|           (1,[],[])|\n",
    "# |        587|    Spain|  Male| 45|     6|       0|            1|        0|             0|       15868481|     0|          2.0|       0.0|              (2,[],[])|       (1,[0],[1.0])|\n",
    "# |        726|   France|Female| 24|     6|       0|            2|        1|             1|        5472403|     0|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# +-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+-------------+----------+-----------------------+--------------------+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 09 - Imputer tratando valores ausentes\n",
    "\n",
    "- Substitui valores ausentes\n",
    "- Usa uma estratégia de substituição: média, mediana ou moda\n",
    "- Pode ainda substituir qualquer outro valor (por exemplo, zero) usando parâmetro setMissingValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors| HP|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|     21|        6|        160|             39| 262| 1646|        0|          1|      4|          4|110|\n",
      "|     21|        6|       null|             39|2875| null|        0|          1|      4|          4|110|\n",
      "|    228|        0|        108|            385| 232| 1861|        1|          1|      4|          1| 93|\n",
      "|    214|        0|       null|            308|3215| 1944|        1|          0|      3|          1|110|\n",
      "|    187|        0|        360|            315|null| 1702|        0|          0|      3|          2|175|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_carros_nan = (\n",
    "    spark.read.format('csv')\n",
    "    .option('header', True)\n",
    "    .option('inferSchema', True)\n",
    "    .option('delimiter', ';')\n",
    "    .load('data/CarrosNAN.csv')\n",
    ")\n",
    "\n",
    "df_carros_nan.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors| HP|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|     21|        6|        160|             39| 262| 1646|        0|          1|      4|          4|110|\n",
      "|     21|        6|        848|             39|2875| null|        0|          1|      4|          4|110|\n",
      "|    228|        0|        108|            385| 232| 1861|        1|          1|      4|          1| 93|\n",
      "|    214|        0|        848|            308|3215| 1944|        1|          0|      3|          1|110|\n",
      "|    187|        0|        360|            315|1318| 1702|        0|          0|      3|          2|175|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Substituindo 0 pela média(default)\n",
    "\n",
    "df_carros_nan_imput = Imputer(\n",
    "    inputCols=['Cilindradas', 'Peso'],\n",
    "    outputCols=['Cilindradas', 'Peso']\n",
    ").fit(df_carros_nan).transform(df_carros_nan)\n",
    "\n",
    "df_carros_nan_imput.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors| HP|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|     21|        6|        160|             39| 262| 1646|        0|          1|      4|          4|110|\n",
      "|     21|        6|        848|             39|2875| null|        0|          1|      4|          4|110|\n",
      "|    228|        6|        108|            385| 232| 1861|        1|          1|      4|          1| 93|\n",
      "|    214|        6|        848|            308|3215| 1944|        1|          0|      3|          1|110|\n",
      "|    187|        6|        360|            315|1318| 1702|        0|          0|      3|          2|175|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Substituindo 0 pela mediana\n",
    "\n",
    "df_carros_0_to_median_imput = Imputer(\n",
    "    inputCol='Cilindros',\n",
    "    outputCol='Cilindros',\n",
    "    missingValue=0,\n",
    "    strategy='median',\n",
    "\n",
    ").fit(df_carros_nan_imput).transform(df_carros_nan_imput)\n",
    "\n",
    "df_carros_0_to_median_imput.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 10 - Polinomial Expansion / Expansão de atributos\n",
    "- Expande um atributo de acordo com o grau, criando novos atributos\n",
    "- Exemplo, dois atributos x e y expandidos com grau 2:\n",
    "- x, x * x, y, x * y, y * y\n",
    "- Entrada deve ser uma coluna com vetor de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------------------------------------------------+\n",
      "|features         |features_polynomial                                           |\n",
      "+-----------------+--------------------------------------------------------------+\n",
      "|[21.0,6.0,160.0] |[21.0,441.0,6.0,126.0,36.0,160.0,3360.0,960.0,25600.0]        |\n",
      "|[21.0,6.0,848.0] |[21.0,441.0,6.0,126.0,36.0,848.0,17808.0,5088.0,719104.0]     |\n",
      "|[228.0,6.0,108.0]|[228.0,51984.0,6.0,1368.0,36.0,108.0,24624.0,648.0,11664.0]   |\n",
      "|[214.0,6.0,848.0]|[214.0,45796.0,6.0,1284.0,36.0,848.0,181472.0,5088.0,719104.0]|\n",
      "|[187.0,6.0,360.0]|[187.0,34969.0,6.0,1122.0,36.0,360.0,67320.0,2160.0,129600.0] |\n",
      "+-----------------+--------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_polinomial = (\n",
    "    df_carros_0_to_median_imput.select('Consumo', 'Cilindros', 'Cilindradas')\n",
    ")\n",
    "\n",
    "df_polinomial_assembler = VectorAssembler(\n",
    "    inputCols=df_polinomial.columns,\n",
    "    outputCol='features'\n",
    ").transform(df_polinomial)\n",
    "\n",
    "df_polymonial_explansion = PolynomialExpansion(\n",
    "    degree=2,\n",
    "    inputCol='features',\n",
    "    outputCol='features_polynomial'\n",
    ").transform(df_polinomial_assembler)\n",
    "\n",
    "\n",
    "df_polymonial_explansion.select(\n",
    "    'features', 'features_polynomial').show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 11 - Normalização de dados com Normalizer\n",
    "- \"Padronizador\" de dados\n",
    "- Parametro p (p-norm) usando para normalização, default 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_car_assembler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/andre/Documents/Projetos/POCs/pocs-pyspark/curso_machine-learning-com-spark-e-pyspark.ipynb Cell 34'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/andre/Documents/Projetos/POCs/pocs-pyspark/curso_machine-learning-com-spark-e-pyspark.ipynb#ch0000033?line=0'>1</a>\u001b[0m df_car_assembler\u001b[39m.\u001b[39mcolumns[:\u001b[39m3\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_car_assembler' is not defined"
     ]
    }
   ],
   "source": [
    "df_car_assembler.columns[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+-----------------+\n",
      "|Consumo|Cilindros|Cilindradas|features         |\n",
      "+-------+---------+-----------+-----------------+\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |\n",
      "|228    |4        |108        |[228.0,4.0,108.0]|\n",
      "|214    |6        |258        |[214.0,6.0,258.0]|\n",
      "|187    |8        |360        |[187.0,8.0,360.0]|\n",
      "+-------+---------+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_car_assembler = df_carros_vector_assembler.select(\n",
    "    'Consumo', 'Cilindros', 'Cilindradas')\n",
    "\n",
    "df_car_assembler = VectorAssembler(\n",
    "    inputCols=df_car_assembler.columns[:3],\n",
    "    outputCol='features'\n",
    ").transform(df_car_assembler)\n",
    "\n",
    "df_car_assembler.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+-----------------+-------------------------------------------------------------+\n",
      "|Consumo|Cilindros|Cilindradas|features         |features_normalized                                          |\n",
      "+-------+---------+-----------+-----------------+-------------------------------------------------------------+\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |[0.11229946524064172,0.03208556149732621,0.8556149732620321] |\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |[0.11229946524064172,0.03208556149732621,0.8556149732620321] |\n",
      "|228    |4        |108        |[228.0,4.0,108.0]|[0.6705882352941176,0.011764705882352941,0.3176470588235294] |\n",
      "|214    |6        |258        |[214.0,6.0,258.0]|[0.4476987447698745,0.012552301255230125,0.5397489539748954] |\n",
      "|187    |8        |360        |[187.0,8.0,360.0]|[0.33693693693693694,0.014414414414414415,0.6486486486486487]|\n",
      "+-------+---------+-----------+-----------------+-------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_car_normalizer = Normalizer(\n",
    "    inputCol='features',\n",
    "    outputCol='features_normalized',\n",
    "    p=1\n",
    ").transform(df_car_assembler)\n",
    "\n",
    "df_car_normalizer.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 12 - Padronização de Dados com StandardScaler\n",
    "- Normaliza os atributos para o desvio padrão ou média zero.\n",
    "- withStd: transforma os dados para o desvio padrão da unidade. Padrão True.\n",
    "- withMean: Antes de transformar, centraliza os dados pela média. Padrão False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+-----------------+-----------------------------------------------------------+\n",
      "|Consumo|Cilindros|Cilindradas|features         |features_std                                               |\n",
      "+-------+---------+-----------+-----------------+-----------------------------------------------------------+\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |[0.24996122082808128,3.359609874407659,0.20137542427273997]|\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |[0.24996122082808128,3.359609874407659,0.20137542427273997]|\n",
      "|228    |4        |108        |[228.0,4.0,108.0]|[2.713864683276311,2.239739916271773,0.13592841138409947]  |\n",
      "|214    |6        |258        |[214.0,6.0,258.0]|[2.5472238693909235,3.359609874407659,0.32471787163979315] |\n",
      "|187    |8        |360        |[187.0,8.0,360.0]|[2.2258451568976763,4.479479832543546,0.4530947046136649]  |\n",
      "+-------+---------+-----------+-----------------+-----------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_escala = StandardScaler(\n",
    "    inputCol='features',\n",
    "    outputCol='features_std',\n",
    "    withStd=True,\n",
    "    withMean=False,\n",
    ").fit(df_car_assembler).transform(df_car_assembler)\n",
    "\n",
    "df_escala.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 13 - Padronização de dados com RobustScaler\n",
    "\n",
    "- Faz a padronização dos dados de acordo com um Quantil\n",
    "- Melhor quando os dados tem outliers se comparado do StandardScaler (Robust)\n",
    "- Parâmetros:\n",
    "    - lower: Quantil inferior usado no cálculo dos intervalos. Padrão 0.25\n",
    "    - upper: Quantil superior usado no cálculo dos intervalos. Padrão 0.75\n",
    "    - withScaling: Dimensiona os dados para o quantil. Padrão True\n",
    "    - withCentering: Centraliza os dados com a mediana antes de transformar. Padrão False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+-----------------+---------------------------------------------+\n",
      "|Consumo|Cilindros|Cilindradas|features         |features_robust_scaler                       |\n",
      "+-------+---------+-----------+-----------------+---------------------------------------------+\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |[0.29166666666666663,1.5,0.16967126193001061]|\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |[0.29166666666666663,1.5,0.16967126193001061]|\n",
      "|228    |4        |108        |[228.0,4.0,108.0]|[3.1666666666666665,1.0,0.11452810180275717] |\n",
      "|214    |6        |258        |[214.0,6.0,258.0]|[2.972222222222222,1.5,0.27359490986214213]  |\n",
      "|187    |8        |360        |[187.0,8.0,360.0]|[2.597222222222222,2.0,0.3817603393425239]   |\n",
      "+-------+---------+-----------+-----------------+---------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_escala_robust_scaler = RobustScaler(\n",
    "    inputCol='features',\n",
    "    outputCol='features_robust_scaler',\n",
    "    withScaling=True,\n",
    "    withCentering=False,\n",
    "    lower=0.25,\n",
    "    upper=0.75\n",
    ").fit(df_car_assembler).transform(df_car_assembler)\n",
    "\n",
    "df_escala_robust_scaler.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 14 - Padronização de Dados com MinMaxScaler\n",
    "\n",
    "- Transforma os dados para os limites de um intervalo. Normalmente entre zero e 1.\n",
    "- Parâmetros:\n",
    "    - Min: limite inferior. Padrão é zero\n",
    "    - Max: limite superior: Padrão é 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+-----------------+-----------------------------------------------+\n",
      "|Consumo|Cilindros|Cilindradas|features         |MinMaxScaler                                   |\n",
      "+-------+---------+-----------+-----------------+-----------------------------------------------+\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |[0.018518518518518517,0.5,0.030235162374020158]|\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |[0.018518518518518517,0.5,0.030235162374020158]|\n",
      "|228    |4        |108        |[228.0,4.0,108.0]|[0.6574074074074073,0.0,0.010824934677118328]  |\n",
      "|214    |6        |258        |[214.0,6.0,258.0]|[0.6141975308641975,0.5,0.06681597611048899]   |\n",
      "|187    |8        |360        |[187.0,8.0,360.0]|[0.5308641975308641,1.0,0.10488988428518103]   |\n",
      "+-------+---------+-----------+-----------------+-----------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_min_max_scaler = MinMaxScaler(\n",
    "    inputCol='features',\n",
    "    outputCol='MinMaxScaler',\n",
    "    min=0.0,\n",
    "    max=1.0\n",
    ").fit(df_car_assembler).transform(df_car_assembler)\n",
    "\n",
    "df_min_max_scaler.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 15 - Padronização de Dados com MaxAbsScaler\n",
    "\n",
    "- Padroniza os dados entre -1 e 1\n",
    "- Não centraliza os dados de nenhuma forma, então dados não perdem suas características de dispersão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+-----------------+-----------------------------------------------+\n",
      "|Consumo|Cilindros|Cilindradas|features         |features_MaxAbsScaler                          |\n",
      "+-------+---------+-----------+-----------------+-----------------------------------------------+\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |[0.061946902654867256,0.75,0.05801305293691081]|\n",
      "|21     |6        |160        |[21.0,6.0,160.0] |[0.061946902654867256,0.75,0.05801305293691081]|\n",
      "|228    |4        |108        |[228.0,4.0,108.0]|[0.6725663716814159,0.5,0.0391588107324148]    |\n",
      "|214    |6        |258        |[214.0,6.0,258.0]|[0.6312684365781711,0.75,0.09354604786076867]  |\n",
      "|187    |8        |360        |[187.0,8.0,360.0]|[0.551622418879056,1.0,0.13052936910804933]    |\n",
      "+-------+---------+-----------+-----------------+-----------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_MaxAbsScaler = MaxAbsScaler(\n",
    "    inputCol='features',\n",
    "    outputCol='features_MaxAbsScaler'\n",
    ").fit(df_car_assembler).transform(df_car_assembler)\n",
    "\n",
    "df_MaxAbsScaler.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 16 - QuantileDiscretizer\n",
    "\n",
    "- Discretrização é a transformação de dados contínuos em discretos\n",
    "- Parâmetro:\n",
    "    - buckets: quantos valores discretos serão usados (não necessariamente utiliza todos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|CreditScore|Geography|Gender|Age|Tenure| Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|        619|   France|Female| 42|     2|       0|            1|        1|             1|       10134888|     1|\n",
      "|        608|    Spain|Female| 41|     1| 8380786|            1|        0|             1|       11254258|     0|\n",
      "|        502|   France|Female| 42|     8| 1596608|            3|        1|             0|       11393157|     1|\n",
      "|        699|   France|Female| 39|     1|       0|            2|        0|             0|        9382663|     0|\n",
      "|        850|    Spain|Female| 43|     2|12551082|            1|        1|             1|         790841|     0|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_churn.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------+\n",
      "|Tenure|Tenure_QuantileDiscretizer|\n",
      "+------+--------------------------+\n",
      "|2     |1.0                       |\n",
      "|1     |0.0                       |\n",
      "|8     |3.0                       |\n",
      "|1     |0.0                       |\n",
      "|2     |1.0                       |\n",
      "|8     |3.0                       |\n",
      "|7     |3.0                       |\n",
      "|4     |1.0                       |\n",
      "|4     |1.0                       |\n",
      "|2     |1.0                       |\n",
      "|6     |2.0                       |\n",
      "|3     |1.0                       |\n",
      "|10    |3.0                       |\n",
      "|5     |2.0                       |\n",
      "|7     |3.0                       |\n",
      "|3     |1.0                       |\n",
      "|1     |0.0                       |\n",
      "|9     |3.0                       |\n",
      "|6     |2.0                       |\n",
      "|6     |2.0                       |\n",
      "+------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Discretizando a coluna Tenure\n",
    "\n",
    "df_churn_QuantileDiscretizer = QuantileDiscretizer(\n",
    "    numBuckets=4,\n",
    "    inputCol='Tenure',\n",
    "    outputCol='Tenure_QuantileDiscretizer'\n",
    ").fit(df_churn).transform(df_churn)\n",
    "\n",
    "(\n",
    "    df_churn_QuantileDiscretizer\n",
    "    .select('Tenure', 'Tenure_QuantileDiscretizer')\n",
    "    .show(20, truncate=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 17 - Transformação com RFormula\n",
    "\n",
    "- Linguagem R permite definir modelo através de fórmula\n",
    "- [variável dependente] ~ [variável independentes]\n",
    "- Variáveis Independentes podem ser definidas através de +\n",
    "- Ponto define todas os atributos – variável dependente\n",
    "- Spark implemente Rformula\n",
    "- Combina variáveis independentes em uma única coluna\n",
    "##### Ex:\n",
    "HP ~ Consumo + Cilindros+ Cilindradas<br>\n",
    "HP ~ .\n",
    "\n",
    "<br>Spark implementa RFormula\n",
    "- Colunas numéricas serão transformadas em double\n",
    "- Strings serão transformadas com StringIndexer, e a última categoria é excluída e então aplica One HotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors| HP|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|     21|        6|        160|             39| 262| 1646|        0|          1|      4|          4|110|\n",
      "|     21|        6|        160|             39|2875| 1702|        0|          1|      4|          4|110|\n",
      "|    228|        4|        108|            385| 232| 1861|        1|          1|      4|          1| 93|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_carros.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+-----------------+-----+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors|HP |features         |label|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+-----------------+-----+\n",
      "|21     |6        |160        |39             |262 |1646 |0        |1          |4      |4          |110|[21.0,6.0,160.0] |110.0|\n",
      "|21     |6        |160        |39             |2875|1702 |0        |1          |4      |4          |110|[21.0,6.0,160.0] |110.0|\n",
      "|228    |4        |108        |385            |232 |1861 |1        |1          |4      |1          |93 |[228.0,4.0,108.0]|93.0 |\n",
      "|214    |6        |258        |308            |3215|1944 |1        |0          |3      |1          |110|[214.0,6.0,258.0]|110.0|\n",
      "|187    |8        |360        |315            |344 |1702 |0        |0          |3      |2          |175|[187.0,8.0,360.0]|175.0|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consumo+Cilindros+Cilindrada\n",
    "\n",
    "df_RFormula = RFormula(\n",
    "    formula='HP ~ Consumo + Cilindros + Cilindradas',\n",
    "    featuresCol='features',\n",
    "    labelCol='label'\n",
    ").fit(df_carros).transform(df_carros)\n",
    "\n",
    "df_RFormula.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 18 - Divisor de Vetores com VectorSlicer\n",
    "\n",
    "- Recebe uma coluna com um vetor de atributos\n",
    "- Cria uma nova coluna, com os atributos especificados pelo índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+---------------+\n",
      "|features                                             |features_slice |\n",
      "+-----------------------------------------------------+---------------+\n",
      "|[21.0,6.0,160.0,39.0,262.0,1646.0,0.0,1.0,4.0,4.0]   |[6.0,160.0,0.0]|\n",
      "|[21.0,6.0,160.0,39.0,2875.0,1702.0,0.0,1.0,4.0,4.0]  |[6.0,160.0,0.0]|\n",
      "|[228.0,4.0,108.0,385.0,232.0,1861.0,1.0,1.0,4.0,1.0] |[4.0,108.0,1.0]|\n",
      "|[214.0,6.0,258.0,308.0,3215.0,1944.0,1.0,0.0,3.0,1.0]|[6.0,258.0,1.0]|\n",
      "|[187.0,8.0,360.0,315.0,344.0,1702.0,0.0,0.0,3.0,2.0] |[8.0,360.0,0.0]|\n",
      "+-----------------------------------------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_vector_slice = VectorSlicer(\n",
    "    inputCol ='features',\n",
    "    outputCol = 'features_slice',\n",
    "    indices = [1, 2, 6]\n",
    ").transform(df_carros_vector_assembler)\n",
    "\n",
    "df_vector_slice.select('features', 'features_slice').show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 19 - Seleção de atributos com  ChiSqSelector (qui-quadrado)\n",
    "\n",
    "- Seleção de atributos: técnica de engenharia de atributos que busca melhorar a performance do modelo através da seleção de um subconjunto de atributos mais relevantes para prever a classe\n",
    "- Usa o teste de independência do qui-quadrado para selecionar os atributos\n",
    "- Recebe uma coluna com um vetor de atributos e produz uma coluna com um vetor de atributos mais relevantes\n",
    "\n",
    "- selectorType: numTopFeatures (padrão), percentile, fpr, fdr, fwe. - numTopFeatures: quantos atributos devem ser selecionados. Método adrão, com valor = 50\n",
    "- percentile: percentual de atributos que devem ser selecionados. Padrão 0.1\n",
    "- fpr e fwe: seleciona atributos que os valores-p estejam abaixo de um parâmetro. Padrão 0.05\n",
    "- fdr: aplica o critério de FDR (False Discovery Rate) . Padrão 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|features_selecionados|\n",
      "+---------------------+\n",
      "|         [160.0,39.0]|\n",
      "|         [160.0,39.0]|\n",
      "|        [108.0,385.0]|\n",
      "|        [258.0,308.0]|\n",
      "|        [360.0,315.0]|\n",
      "|        [225.0,276.0]|\n",
      "|        [360.0,321.0]|\n",
      "|       [1467.0,369.0]|\n",
      "|       [1408.0,392.0]|\n",
      "|       [1676.0,392.0]|\n",
      "|       [1676.0,392.0]|\n",
      "|       [2758.0,307.0]|\n",
      "|       [2758.0,307.0]|\n",
      "|       [2758.0,307.0]|\n",
      "|        [472.0,293.0]|\n",
      "|          [460.0,3.0]|\n",
      "|        [440.0,323.0]|\n",
      "|        [787.0,408.0]|\n",
      "|        [757.0,493.0]|\n",
      "|        [711.0,422.0]|\n",
      "+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_chi_selector = ChiSqSelector(\n",
    "    selectorType = 'fdr', \n",
    "    fdr = 0.01,\n",
    "    featuresCol = 'features', \n",
    "    outputCol = 'features_selecionados',\n",
    "    labelCol = 'HP'\n",
    ").fit(df_carros_vector_assembler).transform(df_carros_vector_assembler)\n",
    "\n",
    "df_chi_selector.select('features_selecionados').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 16 - QuantileDiscretizer"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3556a075bbd99350e89efd66c7151da1cf29c86598df2105d417c263a61f5267"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv-cursos')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
