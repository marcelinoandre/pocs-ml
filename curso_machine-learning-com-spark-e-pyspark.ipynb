{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 01 Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 11:29:21 WARN Utils: Your hostname, andre-UBUNTU20-04 resolves to a loopback address: 127.0.1.1; using 192.168.0.136 instead (on interface wlp2s0)\n",
      "22/05/25 11:29:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/andre/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/25 11:29:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/25 11:29:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.136:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>machine-learning-pyspark-mllib</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2b3ffff400>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    VectorAssembler, \n",
    "    PCA,\n",
    "    Binarizer,\n",
    "    StringIndexer,\n",
    "    IndexToString,\n",
    "    OneHotEncoder,\n",
    "    Imputer,\n",
    "    PolynomialExpansion\n",
    ")\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('machine-learning-pyspark-mllib')\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando CSV, Parquet, JSON e ORC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------+-------------+------+----------+\n",
      "| id|               nome|status|       cidade|vendas|      data|\n",
      "+---+-------------------+------+-------------+------+----------+\n",
      "|  1|   Carminda Pestana| Ativo|  Santa Maria|    23|2020-08-11|\n",
      "|  2|    Deolinda Vilela| Ativo|Novo Hamburgo|    34|2020-03-05|\n",
      "|  3|   Emídio Dornelles| Ativo| Porto Alegre|    34|2020-02-05|\n",
      "|  4|Felisbela Dornelles| Ativo| Porto Alegre|    36|2020-02-05|\n",
      "|  5|     Graça Ornellas| Ativo| Porto Alegre|    12|2020-02-05|\n",
      "|  6|   Matilde Rebouças| Ativo| Porto Alegre|    22|2019-01-05|\n",
      "|  7|    Noêmia   Orriça| Ativo|  Santa Maria|    45|2019-10-05|\n",
      "|  8|      Roque Vásquez| Ativo| Porto Alegre|    65|2020-03-05|\n",
      "|  9|      Uriel Queiroz| Ativo| Porto Alegre|    54|2018-05-05|\n",
      "| 10|   Viviana Sequeira| Ativo| Porto Alegre|     0|2020-09-05|\n",
      "+---+-------------------+------+-------------+------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# csv\n",
    "schema = \"\"\"\n",
    "    id INT,\n",
    "    nome STRING,\n",
    "    status STRING,\n",
    "    cidade STRING,\n",
    "    vendas INT,\n",
    "    data DATE \n",
    "\"\"\"\n",
    "df_despachantes = (\n",
    "    spark.read.format('csv')\n",
    "    .schema(schema=schema)\n",
    "    .load('data/despachantes.csv')\n",
    ")\n",
    "df_despachantes.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----+-------------+---+----------+\n",
      "|_c0|                _c1|  _c2|          _c3|_c4|       _c5|\n",
      "+---+-------------------+-----+-------------+---+----------+\n",
      "|  1|   Carminda Pestana|Ativo|  Santa Maria| 23|2020-08-11|\n",
      "|  2|    Deolinda Vilela|Ativo|Novo Hamburgo| 34|2020-03-05|\n",
      "|  3|   Emídio Dornelles|Ativo| Porto Alegre| 34|2020-02-05|\n",
      "|  4|Felisbela Dornelles|Ativo| Porto Alegre| 36|2020-02-05|\n",
      "|  5|     Graça Ornellas|Ativo| Porto Alegre| 12|2020-02-05|\n",
      "|  6|   Matilde Rebouças|Ativo| Porto Alegre| 22|2019-01-05|\n",
      "|  7|    Noêmia   Orriça|Ativo|  Santa Maria| 45|2019-10-05|\n",
      "|  8|      Roque Vásquez|Ativo| Porto Alegre| 65|2020-03-05|\n",
      "|  9|      Uriel Queiroz|Ativo| Porto Alegre| 54|2018-05-05|\n",
      "| 10|   Viviana Sequeira|Ativo| Porto Alegre|  0|2020-09-05|\n",
      "+---+-------------------+-----+-------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parquet\n",
    "df_despachantes = (\n",
    "    spark.read.format('parquet')\n",
    "    .option('inferSchema', True)\n",
    "    .load('data/despachantes.parquet')\n",
    ")\n",
    "df_despachantes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+---+-------------------+------+------+\n",
      "|       cidade|       data| id|               nome|status|vendas|\n",
      "+-------------+-----------+---+-------------------+------+------+\n",
      "|  Santa Maria| 2020-08-11|  1|   Carminda Pestana| Ativo|    23|\n",
      "|Novo Hamburgo| 2020-03-05|  2|    Deolinda Vilela| Ativo|    34|\n",
      "| Porto Alegre| 2020-02-05|  3|   Emídio Dornelles| Ativo|    34|\n",
      "| Porto Alegre| 2020-02-05|  4|Felisbela Dornelles| Ativo|    36|\n",
      "| Porto Alegre| 2020-02-05|  5|     Graça Ornellas| Ativo|    12|\n",
      "| Porto Alegre| 2019-01-05|  6|   Matilde Rebouças| Ativo|    22|\n",
      "|  Santa Maria| 2019-10-05|  7|    Noêmia   Orriça| Ativo|    45|\n",
      "| Porto Alegre| 2020-03-05|  8|      Roque Vásquez| Ativo|    65|\n",
      "| Porto Alegre| 2018-05-05|  9|      Uriel Queiroz| Ativo|    54|\n",
      "| Porto Alegre| 2020-09-05| 10|   Viviana Sequeira| Ativo|     0|\n",
      "+-------------+-----------+---+-------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JSON\n",
    "df_despachantes = (\n",
    "    spark.read.format('json')\n",
    "    .option('inferSchema', True)\n",
    "    .load('data/despachantes.json')\n",
    ")\n",
    "df_despachantes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----+-------------+---+----------+\n",
      "|_c0|                _c1|  _c2|          _c3|_c4|       _c5|\n",
      "+---+-------------------+-----+-------------+---+----------+\n",
      "|  1|   Carminda Pestana|Ativo|  Santa Maria| 23|2020-08-11|\n",
      "|  2|    Deolinda Vilela|Ativo|Novo Hamburgo| 34|2020-03-05|\n",
      "|  3|   Emídio Dornelles|Ativo| Porto Alegre| 34|2020-02-05|\n",
      "|  4|Felisbela Dornelles|Ativo| Porto Alegre| 36|2020-02-05|\n",
      "|  5|     Graça Ornellas|Ativo| Porto Alegre| 12|2020-02-05|\n",
      "|  6|   Matilde Rebouças|Ativo| Porto Alegre| 22|2019-01-05|\n",
      "|  7|    Noêmia   Orriça|Ativo|  Santa Maria| 45|2019-10-05|\n",
      "|  8|      Roque Vásquez|Ativo| Porto Alegre| 65|2020-03-05|\n",
      "|  9|      Uriel Queiroz|Ativo| Porto Alegre| 54|2018-05-05|\n",
      "| 10|   Viviana Sequeira|Ativo| Porto Alegre|  0|2020-09-05|\n",
      "+---+-------------------+-----+-------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ORC\n",
    "df_despachantes = (\n",
    "    spark.read.format('orc')\n",
    "    .option('inferSchema', True)\n",
    "    .load('data/despachantes.orc')\n",
    ")\n",
    "df_despachantes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engenharia de Atributos e Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 03 - Vetorização de Atributos com VectorAssembler\n",
    "- Recebe como entrada um data frame com diversos atributos\n",
    "- Produz como saída um único atributo, que é um vetor dos atributos de\n",
    "entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors|HP |\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|21     |6        |160        |39             |262 |1646 |0        |1          |4      |4          |110|\n",
      "|21     |6        |160        |39             |2875|1702 |0        |1          |4      |4          |110|\n",
      "|228    |4        |108        |385            |232 |1861 |1        |1          |4      |1          |93 |\n",
      "|214    |6        |258        |308            |3215|1944 |1        |0          |3      |1          |110|\n",
      "|187    |8        |360        |315            |344 |1702 |0        |0          |3      |2          |175|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_carros = (\n",
    "    spark.read.format('csv')\n",
    "    .option('inferSchema', True)\n",
    "    .option('header', True)\n",
    "    .option('delimiter', ';')\n",
    "    .load('data/Carros.csv')\n",
    ")\n",
    "df_carros.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+\n",
      "|features                                             |\n",
      "+-----------------------------------------------------+\n",
      "|[21.0,6.0,160.0,39.0,262.0,1646.0,0.0,1.0,4.0,4.0]   |\n",
      "|[21.0,6.0,160.0,39.0,2875.0,1702.0,0.0,1.0,4.0,4.0]  |\n",
      "|[228.0,4.0,108.0,385.0,232.0,1861.0,1.0,1.0,4.0,1.0] |\n",
      "|[214.0,6.0,258.0,308.0,3215.0,1944.0,1.0,0.0,3.0,1.0]|\n",
      "|[187.0,8.0,360.0,315.0,344.0,1702.0,0.0,0.0,3.0,2.0] |\n",
      "+-----------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_carros_vector_assembler =  VectorAssembler(\n",
    "    inputCols = df_carros.columns[:-1],\n",
    "    outputCol = 'features'\n",
    ").transform(df_carros)\n",
    "\n",
    "df_carros_vector_assembler.select('features').show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Aula 04 - Geração de Caracterśticas com PCA (Principal Component analysis)\n",
    "\n",
    "- Alta dimensionalidade:\n",
    "    - Menor capacidade de generalização\n",
    "- PCA: Redução de Dimensionalidade\n",
    "- Cria atributos sintéticos, sem compreensão funcional\n",
    "- Estes novos atributos buscam manter as características importantes dos dados\n",
    "- Representação dos atributos originais: projeção\n",
    "- Não permite avaliar importância de atributos e não mais representam o negocio\n",
    "analisado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 11:29:45 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "22/05/25 11:29:45 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+-----------------------------------------------------------+\n",
      "|features                                             |features_pca                                               |\n",
      "+-----------------------------------------------------+-----------------------------------------------------------+\n",
      "|[21.0,6.0,160.0,39.0,262.0,1646.0,0.0,1.0,4.0,4.0]   |[618.7707206779613,-937.712394997354,1231.963352994551]    |\n",
      "|[21.0,6.0,160.0,39.0,2875.0,1702.0,0.0,1.0,4.0,4.0]  |[3112.9887675342197,-161.05746385491523,1191.8619913054383]|\n",
      "|[228.0,4.0,108.0,385.0,232.0,1861.0,1.0,1.0,4.0,1.0] |[640.4959007710695,-1120.718886511042,1320.0756315189049]  |\n",
      "|[214.0,6.0,258.0,308.0,3215.0,1944.0,1.0,0.0,3.0,1.0]|[3466.0956877556673,-149.69421418298353,1401.204178036853] |\n",
      "|[187.0,8.0,360.0,315.0,344.0,1702.0,0.0,0.0,3.0,2.0] |[661.4577445758732,-812.4592128844115,1395.2949328316356]  |\n",
      "+-----------------------------------------------------+-----------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_modelo = PCA(\n",
    "    k = 3,\n",
    "    inputCol = 'features',\n",
    "    outputCol = 'features_pca'\n",
    ").fit(df_carros_vector_assembler)\n",
    "\n",
    "df_carros_pca = pca_modelo.transform(df_carros_vector_assembler)\n",
    "df_carros_pca.select('features', 'features_pca').show(5, truncate = False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 05 - Binarização de Atributos\n",
    "- Parametro threshold\n",
    "- \\> threshold = 1\n",
    "- < threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----------+\n",
      "|sepallength|sepalwidth|petallength|petalwidth|      class|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "|        5.1|       3.5|        1.4|       0.2|Iris-setosa|\n",
      "|        4.9|       3.0|        1.4|       0.2|Iris-setosa|\n",
      "|        4.7|       3.2|        1.3|       0.2|Iris-setosa|\n",
      "|        4.6|       3.1|        1.5|       0.2|Iris-setosa|\n",
      "|        5.0|       3.6|        1.4|       0.2|Iris-setosa|\n",
      "+-----------+----------+-----------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_iris = (\n",
    "    spark.read.format('csv')\n",
    "    .option('inferSchema', True)\n",
    "    .option('header', True)\n",
    "    .load('data/iris.csv')\n",
    ")\n",
    "\n",
    "df_iris.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+----------+-----------+---------------------+\n",
      "|sepallength|sepalwidth|petallength|petalwidth|      class|sepallength_binarizer|\n",
      "+-----------+----------+-----------+----------+-----------+---------------------+\n",
      "|        5.1|       3.5|        1.4|       0.2|Iris-setosa|                  1.0|\n",
      "|        4.9|       3.0|        1.4|       0.2|Iris-setosa|                  0.0|\n",
      "|        4.7|       3.2|        1.3|       0.2|Iris-setosa|                  0.0|\n",
      "|        4.6|       3.1|        1.5|       0.2|Iris-setosa|                  0.0|\n",
      "|        5.0|       3.6|        1.4|       0.2|Iris-setosa|                  1.0|\n",
      "+-----------+----------+-----------+----------+-----------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_iris_binarizer = Binarizer(\n",
    "    threshold = 4.9, \n",
    "    inputCol = 'sepallength',\n",
    "    outputCol = 'sepallength_binarizer'\n",
    ").transform(df_iris)\n",
    "\n",
    "df_iris_binarizer.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 06 - Indexação de Texto com StringIndexer\n",
    "\n",
    "- Técnica de Categorical Encoding: transforma categorias em números\n",
    "- Itens mais frequentes recebem os números menores\n",
    "- Você cria um modelo com um conjunto de dados, e usar este modelo para transformar outros conjuntos de dados\n",
    "    - Rótulos não conhecidos encontrados são tratados pelo parâmetro handleInvalid, que pode ter os valores\n",
    "        - Exceção (default): ‘error’\n",
    "        - Omitir: 'skip'\n",
    "        - Colocar “desconhecidos” em uma categoria especial: 'keep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|CreditScore|Geography|Gender|Age|Tenure| Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|        619|   France|Female| 42|     2|       0|            1|        1|             1|       10134888|     1|\n",
      "|        608|    Spain|Female| 41|     1| 8380786|            1|        0|             1|       11254258|     0|\n",
      "|        502|   France|Female| 42|     8| 1596608|            3|        1|             0|       11393157|     1|\n",
      "|        699|   France|Female| 39|     1|       0|            2|        0|             0|        9382663|     0|\n",
      "|        850|    Spain|Female| 43|     2|12551082|            1|        1|             1|         790841|     0|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_churn = (\n",
    "    spark.read.format('csv')\n",
    "    .option('header', True)\n",
    "    .option('inferSchema', True)\n",
    "    .option('delimiter', ';')\n",
    "    .load('data/Churn.csv')\n",
    ")\n",
    "\n",
    "df_churn.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+------+----------+\n",
      "|Geography|Geography_idx|Gender|Gender_idx|\n",
      "+---------+-------------+------+----------+\n",
      "|   France|          0.0|Female|       1.0|\n",
      "|    Spain|          2.0|Female|       1.0|\n",
      "|   France|          0.0|Female|       1.0|\n",
      "|   France|          0.0|Female|       1.0|\n",
      "|    Spain|          2.0|Female|       1.0|\n",
      "+---------+-------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Geography</th><th>Gender</th><th>count(Geography_idx)</th><th>count(Gender_idx)</th></tr>\n",
       "<tr><td>Germany</td><td>Female</td><td>1193</td><td>1193</td></tr>\n",
       "<tr><td>France</td><td>Male</td><td>2753</td><td>2753</td></tr>\n",
       "<tr><td>France</td><td>Female</td><td>2261</td><td>2261</td></tr>\n",
       "<tr><td>Spain</td><td>Male</td><td>1388</td><td>1388</td></tr>\n",
       "<tr><td>Germany</td><td>Male</td><td>1316</td><td>1316</td></tr>\n",
       "<tr><td>Spain</td><td>Female</td><td>1089</td><td>1089</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+------+--------------------+-----------------+\n",
       "|Geography|Gender|count(Geography_idx)|count(Gender_idx)|\n",
       "+---------+------+--------------------+-----------------+\n",
       "|  Germany|Female|                1193|             1193|\n",
       "|   France|  Male|                2753|             2753|\n",
       "|   France|Female|                2261|             2261|\n",
       "|    Spain|  Male|                1388|             1388|\n",
       "|  Germany|  Male|                1316|             1316|\n",
       "|    Spain|Female|                1089|             1089|\n",
       "+---------+------+--------------------+-----------------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_churn_string_idx = StringIndexer(\n",
    "    inputCols = ['Geography', 'Gender'],\n",
    "    outputCols = ['Geography_idx', 'Gender_idx']\n",
    ").fit(df_churn)\n",
    "\n",
    "df_churn_string_idx = model_churn_string_idx.transform(df_churn)\n",
    "df_churn_string_idx.select('Geography', \n",
    "                            'Geography_idx', \n",
    "                            'Gender', \n",
    "                            'Gender_idx'\n",
    "                            ).show(5)\n",
    "\n",
    "df_churn_string_idx.groupBy('Geography', 'Gender').agg(F.count('Geography_idx'), F.count('Gender_idx') )                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 7 - Índice para Texto com IndexToString\n",
    "- As vezes precisamos converter de volta um\n",
    "índice para a categoria\n",
    "    - Explicar o modelo\n",
    "    - Mostrar valores “reais”\n",
    "- IndexToString cria um atributo com a coluna original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------------------+\n",
      "|Geography|Geography_idx|Geography_idx_to_str|\n",
      "+---------+-------------+--------------------+\n",
      "|   France|          0.0|              France|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|   France|          0.0|              France|\n",
      "|   France|          0.0|              France|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|   France|          0.0|              France|\n",
      "|  Germany|          1.0|             Germany|\n",
      "|   France|          0.0|              France|\n",
      "|   France|          0.0|              France|\n",
      "|   France|          0.0|              France|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|   France|          0.0|              France|\n",
      "|   France|          0.0|              France|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|  Germany|          1.0|             Germany|\n",
      "|  Germany|          1.0|             Germany|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|    Spain|          2.0|               Spain|\n",
      "|   France|          0.0|              France|\n",
      "+---------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_churn_index_to_string = IndexToString(\n",
    "    inputCol = 'Geography_idx',\n",
    "    outputCol = 'Geography_idx_to_str'\n",
    ").transform(df_churn_string_idx)\n",
    "\n",
    "df_churn_index_to_string.select('Geography', 'Geography_idx', 'Geography_idx_to_str').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 08 - One Hot Encoding\n",
    "- OneHotEncoding produz um único atributo de saída com uma matriz densa, a partir de n atributos numéricos\n",
    "-  Espera atributos numéricos: Podemos usar StringIndexer para transformar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-------------+----------+-----------------------+--------------------+\n",
      "|Geography|Gender|Geography_idx|Gender_idx|Geography_oneHotEncoder|Gender_oneHotEncoder|\n",
      "+---------+------+-------------+----------+-----------------------+--------------------+\n",
      "|France   |Female|0.0          |1.0       |(2,[0],[1.0])          |(1,[],[])           |\n",
      "|Spain    |Female|2.0          |1.0       |(2,[],[])              |(1,[],[])           |\n",
      "|France   |Female|0.0          |1.0       |(2,[0],[1.0])          |(1,[],[])           |\n",
      "|France   |Female|0.0          |1.0       |(2,[0],[1.0])          |(1,[],[])           |\n",
      "|Spain    |Female|2.0          |1.0       |(2,[],[])              |(1,[],[])           |\n",
      "|Spain    |Male  |2.0          |0.0       |(2,[],[])              |(1,[0],[1.0])       |\n",
      "|France   |Male  |0.0          |0.0       |(2,[0],[1.0])          |(1,[0],[1.0])       |\n",
      "|Germany  |Female|1.0          |1.0       |(2,[1],[1.0])          |(1,[],[])           |\n",
      "+---------+------+-------------+----------+-----------------------+--------------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_one_hot_encoding = OneHotEncoder(\n",
    "    inputCols=['Geography_idx', 'Gender_idx'],\n",
    "    outputCols=['Geography_oneHotEncoder','Gender_oneHotEncoder' ]\n",
    "\n",
    ").fit(df_churn_string_idx)\n",
    "\n",
    "df_one_hot_encoding = model_one_hot_encoding.transform(df_churn_string_idx)\n",
    "df_one_hot_encoding.select( 'Geography', 'Gender','Geography_idx', 'Gender_idx', 'Geography_oneHotEncoder','Gender_oneHotEncoder' ).show(8, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+-------------+----------+-----------------------+--------------------+\n",
    "# |CreditScore|Geography|Gender|Age|Tenure| Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|Geography_idx|Gender_idx|Geography_oneHotEncoder|Gender_oneHotEncoder|\n",
    "# +-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+-------------+----------+-----------------------+--------------------+\n",
    "# |        619|   France|Female| 42|     2|       0|            1|        1|             1|       10134888|     1|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# |        608|    Spain|Female| 41|     1| 8380786|            1|        0|             1|       11254258|     0|          2.0|       1.0|              (2,[],[])|           (1,[],[])|\n",
    "# |        502|   France|Female| 42|     8| 1596608|            3|        1|             0|       11393157|     1|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# |        699|   France|Female| 39|     1|       0|            2|        0|             0|        9382663|     0|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# |        850|    Spain|Female| 43|     2|12551082|            1|        1|             1|         790841|     0|          2.0|       1.0|              (2,[],[])|           (1,[],[])|\n",
    "# |        645|    Spain|  Male| 44|     8|11375578|            2|        1|             0|       14975671|     1|          2.0|       0.0|              (2,[],[])|       (1,[0],[1.0])|\n",
    "# |        822|   France|  Male| 50|     7|       0|            2|        1|             1|         100628|     0|          0.0|       0.0|          (2,[0],[1.0])|       (1,[0],[1.0])|\n",
    "# |        376|  Germany|Female| 29|     4|11504674|            4|        1|             0|       11934688|     1|          1.0|       1.0|          (2,[1],[1.0])|           (1,[],[])|\n",
    "# |        501|   France|  Male| 44|     4|14205107|            2|        0|             1|         749405|     0|          0.0|       0.0|          (2,[0],[1.0])|       (1,[0],[1.0])|\n",
    "# |        684|   France|  Male| 27|     2|13460388|            1|        1|             1|        7172573|     0|          0.0|       0.0|          (2,[0],[1.0])|       (1,[0],[1.0])|\n",
    "# |        528|   France|  Male| 31|     6|10201672|            2|        0|             0|        8018112|     0|          0.0|       0.0|          (2,[0],[1.0])|       (1,[0],[1.0])|\n",
    "# |        497|    Spain|  Male| 24|     3|       0|            2|        1|             0|        7639001|     0|          2.0|       0.0|              (2,[],[])|       (1,[0],[1.0])|\n",
    "# |        476|   France|Female| 34|    10|       0|            2|        1|             0|        2626098|     0|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# |        549|   France|Female| 25|     5|       0|            2|        0|             0|       19085779|     0|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# |        635|    Spain|Female| 35|     7|       0|            2|        1|             1|        6595165|     0|          2.0|       1.0|              (2,[],[])|           (1,[],[])|\n",
    "# |        616|  Germany|  Male| 45|     3|14312941|            2|        0|             1|        6432726|     0|          1.0|       0.0|          (2,[1],[1.0])|       (1,[0],[1.0])|\n",
    "# |        653|  Germany|  Male| 58|     1|13260288|            1|        1|             0|         509767|     1|          1.0|       0.0|          (2,[1],[1.0])|       (1,[0],[1.0])|\n",
    "# |        549|    Spain|Female| 24|     9|       0|            2|        1|             1|        1440641|     0|          2.0|       1.0|              (2,[],[])|           (1,[],[])|\n",
    "# |        587|    Spain|  Male| 45|     6|       0|            1|        0|             0|       15868481|     0|          2.0|       0.0|              (2,[],[])|       (1,[0],[1.0])|\n",
    "# |        726|   France|Female| 24|     6|       0|            2|        1|             1|        5472403|     0|          0.0|       1.0|          (2,[0],[1.0])|           (1,[],[])|\n",
    "# +-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+-------------+----------+-----------------------+--------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aula 09 - Imputer tratando valores ausentes\n",
    "\n",
    "- Substitui valores ausentes\n",
    "- Usa uma estratégia de substituição: média, mediana ou moda\n",
    "- Pode ainda substituir qualquer outro valor (por exemplo, zero) usando parâmetro setMissingValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors| HP|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|     21|        6|        160|             39| 262| 1646|        0|          1|      4|          4|110|\n",
      "|     21|        6|       null|             39|2875| null|        0|          1|      4|          4|110|\n",
      "|    228|        0|        108|            385| 232| 1861|        1|          1|      4|          1| 93|\n",
      "|    214|        0|       null|            308|3215| 1944|        1|          0|      3|          1|110|\n",
      "|    187|        0|        360|            315|null| 1702|        0|          0|      3|          2|175|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_carros_nan = (\n",
    "    spark.read.format('csv')\n",
    "    .option('header', True)\n",
    "    .option('inferSchema', True)\n",
    "    .option('delimiter', ';')\n",
    "    .load('data/CarrosNAN.csv')\n",
    ")\n",
    "\n",
    "df_carros_nan.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors| HP|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|     21|        6|        160|             39| 262| 1646|        0|          1|      4|          4|110|\n",
      "|     21|        6|        848|             39|2875| null|        0|          1|      4|          4|110|\n",
      "|    228|        0|        108|            385| 232| 1861|        1|          1|      4|          1| 93|\n",
      "|    214|        0|        848|            308|3215| 1944|        1|          0|      3|          1|110|\n",
      "|    187|        0|        360|            315|1318| 1702|        0|          0|      3|          2|175|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Substituindo 0 pela média(default)\n",
    "\n",
    "df_carros_nan_imput = Imputer(\n",
    "    inputCols = ['Cilindradas', 'Peso'],\n",
    "    outputCols = ['Cilindradas', 'Peso']\n",
    ").fit(df_carros_nan).transform(df_carros_nan)\n",
    "\n",
    "df_carros_nan_imput.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors| HP|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|     21|        6|        160|             39| 262| 1646|        0|          1|      4|          4|110|\n",
      "|     21|        6|        848|             39|2875| null|        0|          1|      4|          4|110|\n",
      "|    228|        6|        108|            385| 232| 1861|        1|          1|      4|          1| 93|\n",
      "|    214|        6|        848|            308|3215| 1944|        1|          0|      3|          1|110|\n",
      "|    187|        6|        360|            315|1318| 1702|        0|          0|      3|          2|175|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Substituindo 0 pela mediana\n",
    "\n",
    "df_carros_0_to_median_imput = Imputer(\n",
    "    inputCol = 'Cilindros',\n",
    "    outputCol = 'Cilindros',\n",
    "    missingValue = 0,\n",
    "    strategy = 'median',\n",
    "    \n",
    ").fit(df_carros_nan_imput).transform(df_carros_nan_imput)\n",
    "\n",
    "df_carros_0_to_median_imput.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 10 - Polinomial Expansion / Expansão de atributos\n",
    "- Expande um atributo de acordo com o grau, criando novos atributos\n",
    "- Exemplo, dois atributos x e y expandidos com grau 2:\n",
    "- x, x * x, y, x * y, y * y\n",
    "- Entrada deve ser uma coluna com vetor de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------------------------------------------------+\n",
      "|features         |features_polynomial                                           |\n",
      "+-----------------+--------------------------------------------------------------+\n",
      "|[21.0,6.0,160.0] |[21.0,441.0,6.0,126.0,36.0,160.0,3360.0,960.0,25600.0]        |\n",
      "|[21.0,6.0,848.0] |[21.0,441.0,6.0,126.0,36.0,848.0,17808.0,5088.0,719104.0]     |\n",
      "|[228.0,6.0,108.0]|[228.0,51984.0,6.0,1368.0,36.0,108.0,24624.0,648.0,11664.0]   |\n",
      "|[214.0,6.0,848.0]|[214.0,45796.0,6.0,1284.0,36.0,848.0,181472.0,5088.0,719104.0]|\n",
      "|[187.0,6.0,360.0]|[187.0,34969.0,6.0,1122.0,36.0,360.0,67320.0,2160.0,129600.0] |\n",
      "+-----------------+--------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_polinomial = (\n",
    "    df_carros_0_to_median_imput.select('Consumo', 'Cilindros', 'Cilindradas')\n",
    ")\n",
    "\n",
    "df_polinomial_assembler = VectorAssembler(\n",
    "    inputCols = df_polinomial.columns,\n",
    "    outputCol = 'features'\n",
    ").transform(df_polinomial)\n",
    "\n",
    "df_polymonial_explansion = PolynomialExpansion(\n",
    "    degree=2,\n",
    "    inputCol='features',\n",
    "    outputCol = 'features_polynomial'\n",
    ").transform(df_polinomial_assembler)\n",
    "\n",
    "\n",
    "df_polymonial_explansion.select('features', 'features_polynomial').show(5, truncate = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 00 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 00 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 00 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 00 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 00 ..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3556a075bbd99350e89efd66c7151da1cf29c86598df2105d417c263a61f5267"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv-cursos')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
